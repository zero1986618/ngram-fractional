using System;

namespace ngram
{
    abstract class Discount
    {
        public bool Interpolate;
        public virtual double discount(long count, long totalCount, long vocabSize)
        {
            return 1.0;
        }
        // weight given to the lower-order distribution when interpolating high-order estimates (none by default)
        public virtual double LowerOrderWeight(long totalCount, long observedVocab, long min2Vocab, long min3Vocab)
        {
            return 0.0;
        }

        // check if discounting disabled
        public virtual bool Nodiscount()
        {
            return false;
        }

        // dummy estimator for when there is nothing to estimate
        public virtual bool Estimate(BinaryFile binaryFile, int order)
        {
            return true;
        }

        // dummy estimator for when there is nothing to estimate
        public virtual bool Estimate(NGramCounts nGramCounts, int order)
        {
            return true;
        }
        public virtual void PrepareCounts(BinaryFile binaryFile, int order, int maxOrder)
        {
        }
        public virtual void PrepareCounts(NGramCounts nGramCounts, int order, int maxOrder)
        {
        }
        public const int GtDefaultMinCount = 1;
        public const int GtDefaultMaxCount = 5;
        public static int[] gtmin = new[] {1, 1, 1, 2, 2, 2, 2, 2, 2, 2};
        public static int[] gtmax = new[] {5, 1, 7, 7, 7, 7, 7, 7, 7, 7};
    }
    class GoodTuring : Discount
    {
        public GoodTuring(int mincount = GtDefaultMinCount, int maxcount = GtDefaultMaxCount)
        {
            _minCount = mincount;
            _maxCount = maxcount;
            _discountCoeffs = new double[_maxCount + 1];
            _discountCoeffs[0] = 1;
        }
        public override double discount(long count, long totalCount, long vocabSize)
        {
            if (count <= 0)
                return 1;
            if (count < _minCount)
                return 0;
            return count > _maxCount ? 1.0 : _discountCoeffs[count];
        }
        public override bool Nodiscount()
        {
            return _minCount <= 1 && _maxCount <= 0;
        }
        public override bool Estimate(BinaryFile binaryFile, int order)
        {
            long[] countsOfCounts = new long[_maxCount + 1];
            int[] context = new int[order + 1];
            BinLMIter binLMIter = new BinLMIter(binaryFile, order);
            while (binLMIter.MoveNext(ref context))
            {
                //if (Vocab.IsNonEvent(mkeys[order - 1]))
                //    continue;
                if (context[context.Length - 1] <= _maxCount + 1)
                    countsOfCounts[context[context.Length - 1]]++;
            }
            return Estimate(countsOfCounts);
        }
        bool Estimate(long[] countsOfCounts)
        {
            if (countsOfCounts[1] == 0)
            {
                Console.Error.WriteLine("Warning: no singleton counts");
                _maxCount = 0;
            }
            while (_maxCount > 0 && countsOfCounts[_maxCount + 1] == 0)
            {
                Console.Error.WriteLine("warning: count of count {0} is zero -- lowering maxcount\n", _maxCount + 1);
                _maxCount--;
            }
            if (_maxCount <= 0)
                Console.Error.WriteLine("GT discounting disabled\n");
            else
            {
                double commonTerm = (_maxCount + 1) * (double)countsOfCounts[_maxCount + 1] / countsOfCounts[1];
                for (int i = 1; i <= _maxCount; i++)
                {
                    double coeff = 1.0;
                    if (countsOfCounts[i] == 0)
                        Console.Error.WriteLine("warning: count of count {0} is zero\n", i);
                    else
                    {
                        double coeff0 = (i + 1) * (double)countsOfCounts[i + 1] / (i * (double)countsOfCounts[i]);
                        coeff = (coeff0 - commonTerm) / (1.0 - commonTerm);
                        if (!double.IsInfinity(coeff) || coeff <= ProbEpsilon || coeff0 > 1.0)
                        {
                            Console.Error.WriteLine("warning: discount coeff {0} is out of range: {1}", i, coeff);
                            coeff = 1.0;
                        }
                    }
                    _discountCoeffs[i] = coeff;
                }
            }
            return false;
        }

        public override bool Estimate(NGramCounts nGramCounts, int order)
        {
            long[] countsOfCounts = new long[_maxCount + 1];
            TrieIterator<int, long> trieIterator = new TrieIterator<int, long>(nGramCounts.Counts, order);
            Trie<int, long> current;
            int[] mkeys = new int[order];
            while (trieIterator.MoveNext(out current, ref mkeys))
            {
                if (nGramCounts.Vocab.IsNonEvent(mkeys[order - 1]))
                    continue;
                if (current.Data <= _maxCount + 1)
                    countsOfCounts[current.Data]++;
            }
            return Estimate(countsOfCounts);
        }
        const double ProbEpsilon = 3e-06;

        private readonly int _minCount;
        private int _maxCount;
        private readonly double[] _discountCoeffs;
    }
    class KneserNey : Discount
    {
        protected long MinCount;		// counts below this are set to 0
        protected double Discount1;		// discounting constant
        protected bool CountsAreModified;	// low-order counts are already modified
        protected bool PrepareCountsAtEnd;	// should we modify counts after computing D
        public KneserNey(int mincount = 0, bool countsAreModified = false, bool prepareCountsAtEnd = false)
        {
            MinCount = mincount;
            Discount1 = 0.0;
            CountsAreModified = countsAreModified;
            PrepareCountsAtEnd = prepareCountsAtEnd;
        }
        public override double discount(long count, long totalCount, long vocabSize)
        {
            if (count <= 0)
                return 1.0;
            if (count < MinCount)
                return 0.0;
            return (count - Discount1)/count;
        }

        public override double LowerOrderWeight(long totalCount, long observedVocab, long min2Vocab, long min3Vocab)
        {
            return (Discount1*observedVocab/totalCount);
        }

        public override bool Estimate(NGramCounts nGramCounts, int order)
        {
            if (!PrepareCountsAtEnd)
                PrepareCounts(nGramCounts, order, nGramCounts.Order);
            long n1 = 0;
            long n2 = 0;
            Trie<int, long> current;
            TrieIterator<int, long> trieIterator = new TrieIterator<int, long>(nGramCounts.Counts, order);
            int[] mkeys = new int[order];
            while (trieIterator.MoveNext(out current, ref mkeys))
            {
                if (nGramCounts.Vocab.IsNonEvent(mkeys[order - 1]))
                    continue;
                if (current.Data == 1)
                    n1++;
                if (current.Data == 2)
                    n2++;
            }
            if (n1 == 0 || n2 == 0)
                return false;
            Discount1 = 1.0*n1/(n1 + n2);
            if (PrepareCountsAtEnd)
                PrepareCounts(nGramCounts, order, nGramCounts.Order);
            return true;
        }

        public override bool Estimate(BinaryFile binaryFile, int order)
        {
            if (!PrepareCountsAtEnd)
                PrepareCounts(binaryFile, order, binaryFile.Order);
            long n1 = 0;
            long n2 = 0;
            BinLMIter binLMIter = new BinLMIter(binaryFile, order);
            int[] mkeys = new int[order + 1];
            while (binLMIter.MoveNext(ref mkeys))
            {
                if (mkeys[order - 1] == 1)
                    continue;
                if (mkeys[mkeys.Length - 1] == 1)
                    n1++;
                if (mkeys[mkeys.Length - 1] == 2)
                    n2++;
            }
            if (n1 == 0 || n2 == 0)
                return false;
            Discount1 = 1.0 * n1 / (n1 + n2);
            if (PrepareCountsAtEnd)
                PrepareCounts(binaryFile, order, binaryFile.Order);
            return true;
        }
        public unsafe override void PrepareCounts(BinaryFile binaryFile, int order, int maxOrder)
        {
            if (CountsAreModified || order >= maxOrder)
                return;
            int start = binaryFile.vocab.BOSIndex;
            for (int i = 0; i < order - 1; i++)
                start = ((InnerNode*) binaryFile.InnerPtr)[binaryFile.PAccCount[i] + start + 1].Child - 1;
            for (int i = binaryFile.PAccCount[order - 1] + start + 1; i < binaryFile.PAccCount[order] - 1; i++)
                ((InnerNode*) binaryFile.InnerPtr)[i].Count = 0;
            int[] keys = new int[order + 2];
            BinLMIter binLMIter = new BinLMIter(binaryFile, order + 1);
            int[] subkeys = new int[order];
            while (binLMIter.MoveNext(ref keys))
            {
                if (keys[keys.Length - 1] > 0)
                {
                    for (int i = 0; i < subkeys.Length; i++)
                        subkeys[i] = keys[i + 1];
                    int addr = binaryFile.FindPrefixNode(subkeys, binaryFile.Order);
                    ((InnerNode*) binaryFile.InnerPtr)[addr].Count++;
                }
            }
            CountsAreModified = true;
        }

        public override void PrepareCounts(NGramCounts nGramCounts, int order, int maxOrder)
        {
            if (CountsAreModified || order >= maxOrder)
                return;            
            Trie<int, long> current;
            int[] words = new int[order];
            TrieIterator<int, long> trieIterator = new TrieIterator<int, long>(nGramCounts.Counts, order);
            while (trieIterator.MoveNext(out current, ref words))
            {                
                if (!nGramCounts.Vocab.IsNonEvent(words[0]))
                    current.Data = 0;
            }
          
            int[] keys = new int[order + 1];
            trieIterator = new TrieIterator<int, long>(nGramCounts.Counts, order + 1);
            while (trieIterator.MoveNext(out current, ref keys))
            {
                if (current.Data > 0)
                {
                    int[] skeys = new int[order];
                    for (int i = 0; i < order; i++)
                        skeys[i] = keys[i + 1];
                    if (order == 3 && skeys[0] == 131 && skeys[1] == 5)
                        Console.WriteLine();
                    Trie<int, long> loCount = nGramCounts.Counts.FindTrie(skeys);
                    loCount.Data += 1;
                }
            }
            CountsAreModified = true;
        }
    }
    class ModifiedKneserNey : KneserNey
    {
        double _discount2;		    // additional discounting constants
        double _discount3Plus;
        public ModifiedKneserNey(int mincount = 0, bool countsAreModified = false, bool prepareCountsAtEnd = false)
            : base(mincount, countsAreModified, prepareCountsAtEnd)
        {
            _discount2 = 0;
            _discount3Plus = 0;
        }

        public override double discount(long count, long totalCount, long vocabSize)
        {
            //if (count <= 0)
            //    return 1.0;
            if (count < MinCount)
                return 0.0;          
            if (count == 1)
                return (count - Discount1) / count;
            if (count == 2)
                return (count - _discount2) / count;
            return (count - _discount3Plus) / count;
        }
        public override double LowerOrderWeight(long totalCount, long observedVocab, long min2Vocab, long min3Vocab)
        {
            return (Discount1 * (observedVocab - min2Vocab) +
                    _discount2 * (min2Vocab - min3Vocab) +
                    _discount3Plus * min3Vocab) / totalCount;
        }
        public override bool Estimate(BinaryFile binaryFile, int order)
        {
            if (!PrepareCountsAtEnd)
                PrepareCounts(binaryFile, order, binaryFile.Order);
            long n1 = 0;
            long n2 = 0;
            long n3 = 0;
            long n4 = 0;
            BinLMIter binLMIter = new BinLMIter(binaryFile, order);
            int[] mkeys = new int[order + 1];
            int nonEventCount = 0;
            while (binLMIter.MoveNext(ref mkeys))
            {
                if (mkeys[order - 1] == 1) //IsNonEvent
                {
                    nonEventCount++;
                    continue;
                }
                if (mkeys[mkeys.Length - 1] == 1)
                    n1++;
                if (mkeys[mkeys.Length - 1] == 2)
                    n2++;
                if (mkeys[mkeys.Length - 1] == 3)
                    n3++;
                if (mkeys[mkeys.Length - 1] == 4)
                    n4++;
            }
            Console.WriteLine("Modified Kneser-Ney under {0} gram", order);
            Console.WriteLine("Modified Kneser-Ney NoneventCount {0}", nonEventCount);
            Console.WriteLine("n1 = {0}", n1);
            Console.WriteLine("n2 = {0}", n2);
            Console.WriteLine("n3 = {0}", n3);
            Console.WriteLine("n4 = {0}", n4);
            double y = (double)n1 / (n1 + 2 * n2);
            Discount1 = 1 - 2 * y * n2 / n1;
            _discount2 = 2 - 3 * y * n3 / n2;
            _discount3Plus = 3 - 4 * y * n4 / n3;
            if (Discount1 < 0.0 || _discount2 < 0.0 || _discount3Plus < 0.0)
            {
                Console.Error.WriteLine("one of modified KneserNey discounts is negative\n");
                return false;
            }
            if (PrepareCountsAtEnd)
                PrepareCounts(binaryFile, order, binaryFile.Order);
            return true;
        }
        public override bool Estimate(NGramCounts nGramCounts, int order)
        {
            if (!PrepareCountsAtEnd)
                PrepareCounts(nGramCounts, order, nGramCounts.Order);
            long n1 = 0;
            long n2 = 0;
            long n3 = 0;
            long n4 = 0;
            Trie<int, long> current;
            TrieIterator<int, long> trieIterator = new TrieIterator<int, long>(nGramCounts.Counts, order);
            int[] mkeys = new int[order];
            int count = 0;
            int nonEventCount = 0;
            while (trieIterator.MoveNext(out current, ref mkeys))
            {
                count++;                
                if (nGramCounts.Vocab.IsNonEvent(mkeys[order - 1]))
                {
                    nonEventCount++;
                    continue;
                }
                if (current.Data == 1)
                    n1++;
                if (current.Data == 2)
                    n2++;
                if (current.Data == 3)
                    n3++;
                if (current.Data == 4)
                    n4++;
            }
            Console.WriteLine("Total {0} {1}-grams", count, order);
            Console.WriteLine("Modified Kneser-Ney NoneventCount {0}", nonEventCount);
            Console.WriteLine("Modified Kneser-Ney under {0} gram", order);
            Console.WriteLine("n1 = {0}", n1);
            Console.WriteLine("n2 = {0}", n2);
            Console.WriteLine("n3 = {0}", n3);
            Console.WriteLine("n4 = {0}", n4);
            double y = (double)n1 / (n1 + 2 * n2);
            Discount1 = 1 - 2 * y * n2 / n1;
            _discount2 = 2 - 3 * y * n3 / n2;
            _discount3Plus = 3 - 4 * y * n4 / n3;
            if (Discount1 < 0.0 || _discount2 < 0.0 || _discount3Plus < 0.0)
            {
                Console.Error.WriteLine("one of modified KneserNey discounts is negative\n");
                return false;
            }
            if (PrepareCountsAtEnd)
                PrepareCounts(nGramCounts, order, nGramCounts.Order);
            return true;
        }
    }
}